# ðŸ§­ Object Pose Estimation Using ArUco Markers (OpenCV)

## A Beginner-Friendly Robotics Computer Vision Project

This project teaches you how robots understand the **3D position and orientation (pose)** of objects using a simple, reliable method: **ArUco markers + camera calibration + OpenCV pose estimation (solvePnP)**.

Even if you're a **total beginner**, this repo guides you step-by-step through:

- What object pose estimation means  
- Why robots need it  
- How ArUco markers work  
- How to calibrate your camera  
- How to detect markers in live video  
- How to compute 3D pose (x, y, z + rotation)  
- How to record the output as a video  
- How to debug issues  

Everything is explained clearly and practically.

---

## ðŸ“Œ Why This Project Matters in Robotics

Robots cannot pick, place, move, or interact with objects unless they know:

### 1ï¸âƒ£ Where is the object?  
**Position in 3D**

### 2ï¸âƒ£ How is it rotated?  
**Orientation (angles / axis direction)**

This is called **6-DoF Pose Estimation** (x, y, z, roll, pitch, yaw).

ArUco markers are widely used in robotics because they are:

- easy to detect  
- robust  
- work even with normal webcams  
- ideal for beginners  

This project gives you a **fully working pose estimation pipeline**, similar to what real industrial robots use in:

- object grasping  
- visual servoing  
- pick-and-place  
- robotic navigation  
- AR applications  

---

## ðŸŽ¯ Project Features

âœ” Detect ArUco markers in **images or webcam video**  
âœ” Estimate **3D pose** (translation + rotation)  
âœ” Draw **3D axes** aligned with marker orientation  
âœ” Save **annotated images**  
âœ” Save **MP4 recordings** of live detection  
âœ” Works with **any webcam**  
âœ” Beginner-friendly explanations  
âœ” Supports camera calibration  

---

# ðŸ—‚ Folder Structure

```text
object-pose-estimation-opencv/
â”œâ”€â”€ detect_and_pose_aruco.py # Main script â€“ detection + 3D pose + live view + recording
â”œâ”€â”€ utils.py # Helper functions (camera loading, drawing 3D axes)
â”œâ”€â”€ cam.py # Creates a synthetic camera calibration file
â”œâ”€â”€ calibrate_aruco.py # (Optional) ArUco-based calibration
â”œâ”€â”€ samples/
â”‚ â”œâ”€â”€ aruco_sample.jpg # Provided sample marker image
â”œâ”€â”€ outputs/ # Auto-generated outputs (created on first run)
â”‚ â”œâ”€â”€ camera.npz # Synthetic OR real camera intrinsics
â”‚ â”œâ”€â”€ camera_aruco.npz # Optional calibration output
â”‚ â”œâ”€â”€ aruco_out.jpg # Annotated sample output (image mode)
â”‚ â”œâ”€â”€ aruco_test_out.jpg
â”‚ â””â”€â”€ aruco_snap_*.jpg # Snapshots saved during webcam runs
â”œâ”€â”€ requirements.txt # OpenCV + numpy + matplotlib
â””â”€â”€ README.md # (THIS FILE)
```

---

# âš™ï¸ Installation

## 1ï¸âƒ£ Install Python 3.10+
Check your version:

```bash
python --version
```

## 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

If ArUco gives errors, install contrib build:

```bash
pip install opencv-contrib-python
```

---

# ðŸŽ¬ Usage â€” Step-by-Step

## âœ” Step 1 â€” Ensure Camera Calibration File Exists

This project uses a synthetic camera calibration file for simplicity.

Run:

```bash
python cam.py
```

This generates:

```bash
outputs/camera.npz
```

It contains:

- `K` â€“ camera intrinsic matrix  
- `dist` â€“ distortion coefficients  
- `reproj_err` â€“ calibration error  

This file is **required** for accurate 3D pose estimation.

---

## âœ” Step 2 â€” Prepare an ArUco Marker

You can either:

### **A) Print an ArUco marker**  
(or show it on another phone/laptop screen)

OR

### **B) Use the provided sample**
```bash
samples/aruco_sample.jpg
```

Hold it in front of the webcam.

---

## âœ” Step 3 â€” Pose Estimation on an Image

```bash
python detect_and_pose_aruco.py --camera-file outputs/camera.npz --source samples/aruco_sample.jpg --out outputs/aruco_out.jpg
```

Output saved to:

```bash
outputs/aruco_out.jpg
```

---

## âœ” Step 4 â€” Live Webcam Detection (No Recording)

```bash
python detect_and_pose_aruco.py --camera-file outputs/camera.npz --source 0
```

### Controls:
- `q` â†’ quit  
- `s` â†’ save a snapshot to `outputs/`

---

## âœ” Step 5 â€” Webcam Detection + Record MP4

```bash
python detect_and_pose_aruco.py --camera-file outputs/camera.npz --source 0 --out outputs/aruco_webcam_record.mp4
```

This will:

- Show live detection  
- Draw 3D axes  
- Record MP4 video to:

```bash
outputs/aruco_webcam_record.mp4
```

---

Use this README as your final documentation for GitHub.

# ðŸ Sample Outputs

Your `outputs/` folder will look like:

```text
outputs/
â”œâ”€â”€ camera.npz # Saved camera intrinsics
â”œâ”€â”€ camera_aruco.npz # Optional real calibration
â”œâ”€â”€ aruco_out.jpg # Annotated sample output
â”œâ”€â”€ aruco_test_out.jpg
â””â”€â”€ aruco_snap_*.jpg # Snapshots captured from webcam
```

---

## ðŸ”¬ How It Works (Simple Explanation)

1ï¸âƒ£ **Detect the marker corners**  
OpenCV finds the 4 corners of each ArUco marker.

2ï¸âƒ£ **Use camera calibration**  
This tells OpenCV how your camera maps 3D â†’ 2D.

3ï¸âƒ£ **Estimate 3D pose**  
OpenCV uses `solvePnP` to compute:  
- Translation (x, y, z)  
- Rotation (rvec)

4ï¸âƒ£ **Draw 3D axes**  
Red = X, Green = Y, Blue = Z â€” shows orientation visually.

---

## ðŸ§  Zero-Knowledge Beginner Explanation

Imagine a robot looking at a cube. It needs to know:
- how far the cube is
- whether it's tilted
- how to grab it
- where its corners are

Your webcam = robot eye  
ArUco marker = robot "cheat code" to understand the object  
OpenCV = robot brain

This repo gives that exact capability.

---

## ðŸ›  Editing the Marker Size (VERY IMPORTANT)

If your printed marker side = **5 cm**, run with:
```bash
--marker-size 0.05
```

If your marker side = **10 cm**, run with:
```bash
--marker-size 0.10
```

If marker side = **20 cm**, run with:
```bash
--marker-size 0.20
```

**If marker size is wrong â†’ the 3D pose will be wrong.**

---

## ðŸ“· Tips for Best Results

- Use good, even lighting  
- Print marker at high quality (matte paper if possible)  
- Avoid strong reflections or gloss  
- Donâ€™t tilt the marker too extremely (keep it visible)  
- Keep at least **20â€“40 cm** from webcam for standard phone/webcams  
- Use `DICT_6X6_250` for robustness:  
```bash
--dict-name DICT_6X6_250
```

---

## ðŸ§© Troubleshooting

- âŒ **â€œNo markers detectedâ€**  
- Show the printed image to the webcam (or screen)  
- Increase lighting  
- Increase marker size on screen or print larger  
- Try `DICT_6X6_250`

- âŒ **Webcam opens but nothing is shown**  
- You must show a physical marker or the sample image to the camera.

- âŒ **Recorded video file is 0 bytes or corrupt**  
- Ensure `opencv-contrib-python` installed (some builds required for video codecs):  
  ```
  pip install opencv-contrib-python
  ```

- âŒ **Pose looks wrong**  
- Verify `--marker-size` matches real marker size  
- Re-check camera calibration (`outputs/camera.npz`)

---

## ðŸ“¸ Example Outputs (open these from the repo to verify)

**Annotated sample (image mode)**  
![Annotated Output](outputs/aruco_out.jpg)

**Alternate annotated output**  
![Annotated Test Output](outputs/aruco_out_DICT_6X6_50.jpg)

**Aruco adaptive thresh output**  
![Annotated Test Output](outputs/aruco_adaptive_thresh.jpg)

**Aruco clahe gray output**  
![Annotated Test Output](outputs/aruco_clahe_gray.jpg)

**Webcam snapshot(s) saved during run**  
![Webcam Snapshot](outputs/aruco_snap_1.jpg)
![Webcam Snapshot](outputs/aruco_snap_2.jpg)
![Webcam Snapshot](outputs/aruco_snap_3.jpg)

> If any of the images above show as broken links in GitHub, run the detection once (image or webcam mode) to generate the corresponding file under `outputs/` and commit it (or replace preview images with your generated outputs).

---

## âœ… Quick reminder â€” common commands

Generate synthetic camera intrinsics (quick start):
```bash
python cam.py
```

Run on sample image:
```bash
python detect_and_pose_aruco.py --camera-file outputs/camera.npz --source samples/aruco_sample.jpg --out outputs/aruco_out.jpg
```

Run live webcam:
```bash
python detect_and_pose_aruco.py --camera-file outputs/camera.npz --source 0
```

Run live webcam + record:
```bash
python detect_and_pose_aruco.py --camera-file outputs/camera.npz --source 0 --out outputs/aruco_webcam_record.mp4
```

---